{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses, regularizers\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing architect\n",
    "\n",
    "# CM: [39 2 4 29]\n",
    "# Accuracy: 0.919\n",
    "# Sensitivity: 0.879\n",
    "# Specificity: 0.951\n",
    "# MCC: 0.836\n",
    "\n",
    "# def create_model():\n",
    "#     # Create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(filters=32, kernel_size=14, strides=1, activation='relu', input_shape=[None,1], name = 'L1'))\n",
    "#     model.add(tf.keras.layers.Dropout(0.2)),  # dropout rate of 0.2\n",
    "#     model.add(Conv1D(filters=32, kernel_size=4, strides=1, activation='relu', name = 'L2'))  # New Conv1D layer\n",
    "#     #model.add(Conv1D(filters=16, kernel_size=3, strides=1, activation='relu', name = 'L3'))  # New Conv1D layer\n",
    "#     model.add(GlobalAveragePooling1D())\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid', name='classification'))\n",
    "#     # Compile model\n",
    "#     adam = tf.keras.optimizers.Adam(learning_rate=1.e-04)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     #model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=8, strides=1, activation='relu', padding = 'same', input_shape=[None,1], name = 'L1'))\n",
    "    model.add(tf.keras.layers.Dropout(0.4)),  # dropout rate of 0.2\n",
    "    model.add(Conv1D(filters=64, kernel_size=6, strides=1, activation='relu', padding ='same', name = 'L2'))  # New Conv1D layer\n",
    "    model.add(Conv1D(filters=32, kernel_size=2, strides=1, activation='relu', name = 'L3'))  # New Conv1D layer\n",
    "    #model.add(Conv1D(filters=16, kernel_size=3, strides=1, activation='relu', name = 'L3'))  # New Conv1D layer\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid', name='classification'))\n",
    "    # Compile model\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=1.e-04)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of Rahul's model\n",
    "# def create_model():\n",
    "#     # Create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(filters=14, kernel_size=10, strides=1, activation='relu', input_shape=[None,1]))\n",
    "#     model.add(GlobalAveragePooling1D())\n",
    "#     model.add(Dense(1, activation='sigmoid', name='classification'))\n",
    "#     # Compile model\n",
    "#     adam = tf.keras.optimizers.Adam(lr=1.e-04)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     #model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = 128\n",
    "np.random.seed(seed)\n",
    "# Split into input (X) and output (y) variables\n",
    "dir = r'C:\\Users\\_Kamat_\\Desktop\\RPI\\ResearchWork\\Papers_\\Effective_Connectivity\\EEG_fNIRS_paper_Brain_informatics\\channelEEG_codes_results_alphaBand\\Results\\Connectivities_LSTMED'\n",
    "csvfilename = 'exp_novST1.csv'\n",
    "# csvfilename = 'EEG_GC_Exp_Nov_T123_svmSelectedConn.csv'\n",
    "data = pd.read_csv(os.path.join(dir,csvfilename)).values\n",
    "m,n = data.shape\n",
    "X0 = data[:,0:n-1]\n",
    "print(X0.shape)\n",
    "X = X0.reshape(X0.shape[0],X0.shape[1],1)\n",
    "print(X.shape)\n",
    "y = data[:,n-1]\n",
    "y = np.array([0 if y[i]==-1 else 1 for i in range(len(y))])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_model() #KerasClassifier(build_fn=create_model, epochs=2000, batch_size=5, verbose=0)\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    # ROC and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    area = auc(fpr, tpr)\n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    # locate the index of the largest g-mean\n",
    "    ix = np.argmax(gmeans)\n",
    "    #print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "    # calculate roc curves\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    area = auc(recall, precision)\n",
    "    # convert to f score\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    #print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "\n",
    "    # Making the Confusion Matrix [tn, fp, fn, tp]\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, (y_pred >= thresholds[ix])).ravel()\n",
    "    N = tn+fp+fn+tp\n",
    "    S = (tp+fn)/N\n",
    "    P = (tp+fp)/N\n",
    "    MCC = ((tp/N)-S*P)/np.sqrt(P*S*(1.-S)*(1.-P))\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    sensitivity = (tp)/(tp+fn)\n",
    "    specificity = (tn)/(tn+fp)\n",
    "\n",
    "    return accuracy, sensitivity, specificity, MCC, tn, fp, fn, tp, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_classifier(XX, yy):\n",
    "    # Assuming classifier_function() returns a trained classifier\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    itest = []\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=False)\n",
    "    #kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    for train, test in kf.split(XX,yy):\n",
    "        x_train, x_test, y_train, y_test = XX[train], XX[test], yy[train], yy[test]\n",
    "\n",
    "        classifier = create_model() #KerasClassifier(build_fn=create_model, epochs=2000, batch_size=5, verbose=0)\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "        classifier.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5000, batch_size=8, shuffle=True, verbose=0, callbacks=[es]) #, callbacks=[es]\n",
    "        # Predicting the Test set results\n",
    "        k_pred = classifier.predict(x_test)\n",
    "        y_true = np.append(y_true, y_test)\n",
    "        y_pred = np.append(y_pred, k_pred)\n",
    "    metrics = model_performance(y_true, y_pred) #tuple of metrics\n",
    "    \n",
    "    return metrics\n",
    "# Initialize lists to store feature indices and corresponding accuracies\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "accuracies = []\n",
    "# Iterate over each feature, dropping one at a time\n",
    "for i in range(X.shape[1]):   #range(X.shape[1])\n",
    "    X_reduced = np.delete(X, i, axis=1)  # remove one feature\n",
    "    # Evaluate accuracy with reduced feature set\n",
    "    metrics = evaluate_classifier(X_reduced, y)\n",
    "    reduced_accuracy = metrics[0] #extract accuracy\n",
    "    # Append the accuracy and feature index to lists\n",
    "    accuracies.append(reduced_accuracy)\n",
    "#accuracies.append([0.86,0.59,0.71,0.93,0.78,0.84,0.94,0.93,0.5])\n",
    "accuracies = np.squeeze(accuracies)\n",
    "sorted_indices = np.argsort(accuracies)\n",
    "print(accuracies)\n",
    "print(sorted_indices)\n",
    "\n",
    "feature_ranking = [feature_indices[i] for i in sorted_indices]\n",
    "accuracies_ranked = [accuracies[i] for i in sorted_indices]\n",
    "print(feature_ranking[:10]) # select the top 10 features\n",
    "\n",
    "# # Print the ranked features and their corresponding accuracies\n",
    "# for rank, (feature_index, accuracy) in enumerate(zip(feature_ranking, accuracies_ranked), 1):\n",
    "#     print(f\"Rank {rank}: Feature {feature_index}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)\n",
    "print(accuracies_ranked)\n",
    "print(feature_ranking)\n",
    "print(X[:,feature_ranking[:10],:].shape)\n",
    "print(X[:,feature_ranking[:10],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy using all features\n",
    "initial_model_metrics = evaluate_classifier(X, y)  #accuracy, sensitivity, specificity, MCC, (tn, fp, fn, tp)\n",
    "accuracies = []\n",
    "# Final model test with top 10 features.\n",
    "X_final = X[:,feature_ranking[:10],:]\n",
    "final_model_metrics = evaluate_classifier(X_final, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC\n",
    "def plot_model_performace(metrics, type):\n",
    "    y_true, y_pred = metrics[-2],metrics[-1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    area = auc(fpr, tpr)\n",
    "\n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    # locate the index of the largest g-mean\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(area))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve '+str(type))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # calculate roc curves\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    area = auc(recall, precision)\n",
    "    # convert to f score\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "\n",
    "    # plot the roc curve for the model\n",
    "    plt.figure()\n",
    "    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
    "    plt.plot([0,1], [no_skill,no_skill], linestyle='--')\n",
    "    plt.plot(recall, precision, marker='.', label='AUC = {:.3f}'.format(area))\n",
    "    #plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.title('PR curve '+str(type))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Making the Confusion Matrix [tn, fp, fn, tp]\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, (y_pred >= thresholds[ix])).ravel()\n",
    "    N = tn+fp+fn+tp\n",
    "    S = (tp+fn)/N\n",
    "    P = (tp+fp)/N\n",
    "    MCC = ((tp/N)-S*P)/np.sqrt(P*S*(1.-S)*(1.-P))\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    sensitivity = (tp)/(tp+fn)\n",
    "    specificity = (tn)/(tn+fp)\n",
    "\n",
    "    print(\"CM: [%d %d %d %d]\" %(tn, fp, fn, tp))\n",
    "    print(\"Accuracy: %0.3f\" %(accuracy))\n",
    "    print(\"Sensitivity: %0.3f\" %(sensitivity))\n",
    "    print(\"Specificity: %0.3f\" %(specificity))\n",
    "    print(\"MCC: %0.3f\" %(MCC))\n",
    "\n",
    "    # from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "    from matplotlib import rcParams\n",
    "    #rcParams['font.sans-serif'] = ['calibri']  # You can change 'Arial' to any other desired font\n",
    "    rcParams['font.size'] = 14\n",
    "    tn, fp, fn, tp = metrics[-6:-2]\n",
    "    conf_matrix = [[tn, fp],\n",
    "                [fn, tp]]\n",
    "    conf_matrix =confusion_matrix(y_true, (y_pred >= thresholds[ix]))\n",
    "    # Plot the confusion matrix\n",
    "    labels = ['Novice', 'Expert']\n",
    "    # plot_confusion_matrix(conf_matrix, display_labels=labels, cmap=plt.cm.Blues, normalize=None)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=labels)\n",
    "    disp.plot()\n",
    "    plt.title('CM '+str(type))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performace(initial_model_metrics, type= 'All connectivity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performace(final_model_metrics, type= 'Selected connectivity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1DCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
